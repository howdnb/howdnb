from simhash import Simhash
import jieba
import sys
import re
import gensim

# 获取文件内容
def get_file(path):
    with open(path,'r',encoding="UTF-8") as f:
       line = f.readline()
       str=""
       while line:
           str=str+line
           line=f.readline()
    return str

#将获取到的文本内容使用jieba库进行分词并进行过滤
def cut(str):
    str=jieba.cut(str)
    result=[]
    for flag in str:     #将文本中除英文和中文外的其它过滤掉
        if(re.match(u"[a-zA-Z0-9\u4e00-\u9fa5]",flag)):
            result.append(flag)
        else:
            pass
    return result

def calculate_similarity(text1,text2):
texts=[text1,text2]
    dictionary=gensim.corpora.Dictionary(texts)
    corpus=[dictionary.doc2bow(text) for text in texts]
    similarity = gensim.similarities.Similarity('-Similarity-index', corpus, num_features=len(dictionary))
    test_corpus_1 = dictionary.doc2bow(text1)
    cosine_sim = similarity[test_corpus_1][1]
    return cosine_sim
